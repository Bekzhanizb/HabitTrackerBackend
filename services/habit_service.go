package services

import (
	"fmt"
	"sync"
	"time"

	"github.com/Bekzhanizb/HabitTrackerBackend/cache"
	"github.com/Bekzhanizb/HabitTrackerBackend/db"
	"github.com/Bekzhanizb/HabitTrackerBackend/models"
	"go.uber.org/zap"
)

type HabitStats struct {
	HabitID        uint    `json:"habit_id"`
	TotalLogs      int     `json:"total_logs"`
	CompletedLogs  int     `json:"completed_logs"`
	CompletionRate float64 `json:"completion_rate"`
	CurrentStreak  int     `json:"current_streak"`
	LongestStreak  int     `json:"longest_streak"`
	Error          error   `json:"-"`
}

type UserHabitStats struct {
	UserID         uint          `json:"user_id"`
	TotalHabits    int           `json:"total_habits"`
	ActiveHabits   int           `json:"active_habits"`
	OverallRate    float64       `json:"overall_completion_rate"`
	HabitStats     []HabitStats  `json:"habit_stats"`
	ProcessingTime time.Duration `json:"processing_time_ms"`
}

/*
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ĞĞ‘ĞĞ¡ĞĞĞ’ĞĞĞ˜Ğ• Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ¯ CONCURRENCY (GOROUTINES + CHANNELS)    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. ĞĞ•Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞ«Ğ• Ğ’Ğ«Ğ§Ğ˜Ğ¡Ğ›Ğ•ĞĞ˜Ğ¯:
   - Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞºĞ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ÑÑ ĞĞ•Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞ
   - ĞĞµÑ‚ shared state Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸ÑĞ¼Ğ¸
   - Ğ˜Ğ´ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ°

2. I/O ĞĞŸĞ•Ğ ĞĞ¦Ğ˜Ğ˜:
   - ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ³Ğ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ° Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ DB query
   - Database queries Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒÑÑ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
   - ĞŸĞ¾ĞºĞ° Ğ¾Ğ´Ğ½Ğ° Ğ³Ğ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ° Ğ¶Ğ´Ñ‘Ñ‚ DB, Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚

3. ĞŸĞ ĞĞ˜Ğ—Ğ’ĞĞ”Ğ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞĞ¡Ğ¢Ğ¬:
   ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾: 10 Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞµĞº Ã— 50ms = 500ms
   ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾: max(50ms) + overhead â‰ˆ 60ms
   Ğ£Ğ¡ĞšĞĞ Ğ•ĞĞ˜Ğ•: ~8x Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ!

4. ĞœĞĞ¡Ğ¨Ğ¢ĞĞ‘Ğ˜Ğ Ğ£Ğ•ĞœĞĞ¡Ğ¢Ğ¬:
   - ĞŸÑ€Ğ¸ Ñ€Ğ¾ÑÑ‚Ğµ Ñ‡Ğ¸ÑĞ»Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾
   - Ğ£ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ 20-30 Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞµĞº
   - Ğ‘ĞµĞ· concurrency: 30 Ã— 50ms = 1.5 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ (Ğ¿Ğ»Ğ¾Ñ…Ğ¾!)
   - Ğ¡ concurrency: ~70ms (Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾!)

5. Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ• CHANNELS:
   - statsChan - Ğ´Ğ»Ñ ÑĞ±Ğ¾Ñ€Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¾Ñ‚ Ğ³Ğ¾Ñ€ÑƒÑ‚Ğ¸Ğ½
   - errChan - Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
   - WaitGroup - Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
*/

// CalculateUserHabitStatsConcurrently - MAIN CONCURRENT FUNCTION
func CalculateUserHabitStatsConcurrently(userID uint, logger *zap.Logger) (*UserHabitStats, error) {
	startTime := time.Now()

	// Check cache first
	cacheKey := fmt.Sprintf("user_stats:%d", userID)
	var cachedStats UserHabitStats
	if err := cache.Get(cacheKey, &cachedStats); err == nil {
		logger.Info("cache_hit", zap.String("key", cacheKey))
		return &cachedStats, nil
	}

	// Get all user habits
	var habits []models.Habit
	if err := db.DB.Where("user_id = ?", userID).Find(&habits).Error; err != nil {
		return nil, err
	}

	if len(habits) == 0 {
		return &UserHabitStats{UserID: userID}, nil
	}

	// ğŸ”¥ Ğ¡ĞĞ—Ğ”ĞĞĞœ CHANNEL Ğ”Ğ›Ğ¯ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’
	statsChan := make(chan HabitStats, len(habits))
	var wg sync.WaitGroup

	// ğŸš€ Ğ—ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ Ğ“ĞĞ Ğ£Ğ¢Ğ˜ĞĞ£ Ğ”Ğ›Ğ¯ ĞšĞĞ–Ğ”ĞĞ™ ĞŸĞ Ğ˜Ğ’Ğ«Ğ§ĞšĞ˜
	for _, habit := range habits {
		wg.Add(1)
		// ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ³Ğ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ĞŸĞĞ ĞĞ›Ğ›Ğ•Ğ›Ğ¬ĞĞ!
		go func(h models.Habit) {
			defer wg.Done()
			stats := calculateSingleHabitStats(h.ID, logger)
			statsChan <- stats // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² channel
		}(habit)
	}

	// Ğ—Ğ°ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ channel ĞºĞ¾Ğ³Ğ´Ğ° Ğ²ÑĞµ Ğ³Ğ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ñ‹ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°Ñ‚ÑÑ
	go func() {
		wg.Wait()
		close(statsChan)
	}()

	// ğŸ“Š Ğ¡ĞĞ‘Ğ˜Ğ ĞĞ•Ğœ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« Ğ˜Ğ— CHANNEL
	var habitStats []HabitStats
	var totalRate float64
	activeCount := 0

	// Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¸Ğ· channel Ğ¿Ğ¾ĞºĞ° Ğ¾Ğ½ Ğ½Ğµ Ğ·Ğ°ĞºÑ€Ğ¾ĞµÑ‚ÑÑ
	for stat := range statsChan {
		if stat.Error != nil {
			logger.Warn("habit_stats_error",
				zap.Uint("habit_id", stat.HabitID),
				zap.Error(stat.Error),
			)
			continue
		}
		habitStats = append(habitStats, stat)
		totalRate += stat.CompletionRate
	}

	for _, h := range habits {
		if h.IsActive {
			activeCount++
		}
	}

	overallRate := 0.0
	if len(habitStats) > 0 {
		overallRate = totalRate / float64(len(habitStats))
	}

	result := &UserHabitStats{
		UserID:         userID,
		TotalHabits:    len(habits),
		ActiveHabits:   activeCount,
		OverallRate:    overallRate,
		HabitStats:     habitStats,
		ProcessingTime: time.Since(startTime),
	}

	// Cache Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
	cache.Set(cacheKey, result, 5*time.Minute)

	logger.Info("stats_calculated_concurrently",
		zap.Uint("user_id", userID),
		zap.Int("habits_count", len(habits)),
		zap.Duration("duration", result.ProcessingTime),
	)

	return result, nil
}

func calculateSingleHabitStats(habitID uint, logger *zap.Logger) HabitStats {
	stats := HabitStats{HabitID: habitID}

	var logs []models.HabitLog
	if err := db.DB.Where("habit_id = ?", habitID).
		Order("date DESC").
		Find(&logs).Error; err != nil {
		stats.Error = err
		return stats
	}

	stats.TotalLogs = len(logs)
	completedCount := 0

	for _, log := range logs {
		if log.IsCompleted {
			completedCount++
		}
	}
	stats.CompletedLogs = completedCount

	if stats.TotalLogs > 0 {
		stats.CompletionRate = float64(completedCount) / float64(stats.TotalLogs) * 100
	}

	// Calculate streaks
	currentStreak := 0
	longestStreak := 0
	tempStreak := 0

	for i, log := range logs {
		if log.IsCompleted {
			tempStreak++
			if i == 0 {
				currentStreak = tempStreak
			}
			if tempStreak > longestStreak {
				longestStreak = tempStreak
			}
		} else {
			if i == 0 {
				currentStreak = 0
			}
			tempStreak = 0
		}
	}

	stats.CurrentStreak = currentStreak
	stats.LongestStreak = longestStreak

	return stats
}

/*
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  WORKER POOL PATTERN - Ğ”Ğ›Ğ¯ ĞœĞĞ¡Ğ¡ĞĞ’Ğ«Ğ¥ ĞĞŸĞ•Ğ ĞĞ¦Ğ˜Ğ™                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ĞĞ‘ĞĞ¡ĞĞĞ’ĞĞĞ˜Ğ•:
- ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹
- ĞŸÑ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºÑƒ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
- ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼
*/

type NotificationJob struct {
	UserID  uint
	Message string
	Type    string
}

func ProcessNotificationsConcurrently(jobs []NotificationJob, workerCount int, logger *zap.Logger) {
	jobChan := make(chan NotificationJob, len(jobs))
	resultChan := make(chan error, len(jobs))
	var wg sync.WaitGroup

	// ğŸ”¥ Ğ—ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ WORKER POOL
	for i := 0; i < workerCount; i++ {
		wg.Add(1)
		go notificationWorker(i, jobChan, resultChan, &wg, logger)
	}

	// ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ² channel
	for _, job := range jobs {
		jobChan <- job
	}
	close(jobChan)

	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
	successCount := 0
	errorCount := 0
	for err := range resultChan {
		if err != nil {
			errorCount++
		} else {
			successCount++
		}
	}

	logger.Info("notifications_processed",
		zap.Int("success", successCount),
		zap.Int("errors", errorCount),
		zap.Int("workers", workerCount),
	)
}

func notificationWorker(id int, jobs <-chan NotificationJob, results chan<- error, wg *sync.WaitGroup, logger *zap.Logger) {
	defer wg.Done()

	for job := range jobs {
		time.Sleep(50 * time.Millisecond) // Simulate sending

		logger.Info("notification_sent",
			zap.Int("worker_id", id),
			zap.Uint("user_id", job.UserID),
			zap.String("type", job.Type),
		)

		results <- nil
	}
}

/*
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  BULK OPERATIONS WITH GOROUTINES                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
*/

func BulkUpdateHabitsActiveStatus(habitIDs []uint, isActive bool, logger *zap.Logger) error {
	if len(habitIDs) == 0 {
		return nil
	}

	errChan := make(chan error, len(habitIDs))
	var wg sync.WaitGroup

	// ğŸš€ ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ĞºĞ°Ğ¶Ğ´ÑƒÑ Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞºÑƒ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³Ğ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ğµ
	for _, id := range habitIDs {
		wg.Add(1)
		go func(habitID uint) {
			defer wg.Done()

			if err := db.DB.Model(&models.Habit{}).
				Where("id = ?", habitID).
				Update("is_active", isActive).Error; err != nil {
				errChan <- fmt.Errorf("failed to update habit %d: %w", habitID, err)
				return
			}

			cache.Delete(fmt.Sprintf("habit:%d", habitID))
			errChan <- nil
		}(id)
	}

	go func() {
		wg.Wait()
		close(errChan)
	}()

	for err := range errChan {
		if err != nil {
			logger.Error("bulk_update_error", zap.Error(err))
			return err
		}
	}

	logger.Info("bulk_update_completed",
		zap.Int("count", len(habitIDs)),
		zap.Bool("is_active", isActive),
	)

	return nil
}
